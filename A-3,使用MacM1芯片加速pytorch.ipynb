{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea02e6fd",
   "metadata": {},
   "source": [
    "# Mac M1 芯片加速pytorch指南"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86314b9",
   "metadata": {},
   "source": [
    "参考文章:\n",
    "\n",
    "《PyTorch宣布支持苹果M1芯片GPU加速：训练快6倍，推理提升21倍》 https://zhuanlan.zhihu.com/p/516920793\n",
    "\n",
    "《MacbookM1芯片深度学习环境配置最全教程：简明安装开发TensorFlow与PyTorch》https://zhuanlan.zhihu.com/p/483551833\n",
    "\n",
    "《一文解释conda,pip,anaconda,miniconda,miniforge》 https://zhuanlan.zhihu.com/p/518926990\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec75498",
   "metadata": {},
   "source": [
    "## 一，加速原理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27edfe53",
   "metadata": {},
   "source": [
    "* Question1，Mac M1芯片 为什么可以用来加速 pytorch？\n",
    "\n",
    "因为 Mac M1芯片不是一个单纯的一个CPU芯片，而是包括了CPU(中央处理器)，GPU(图形处理器)，NPU(神经网络引擎)，以及统一内存单元等众多组件的一块集成芯片。由于Mac M1芯片集成了GPU组件，所以可以用来加速pytorch.\n",
    "\n",
    "* Question2，Mac M1芯片 上GPU的的显存有多大？\n",
    "\n",
    "Mac M1芯片的CPU和GPU使用统一的内存单元。所以Mac M1芯片的能使用的显存大小就是 Mac 电脑的内存大小。\n",
    "\n",
    "* Question3，使用Mac M1芯片加速 pytorch 需要安装 cuda后端吗？\n",
    "\n",
    "不需要，cuda是适配nvidia的GPU的，Mac M1芯片中的GPU适配的加速后端是mps，在Mac对应操作系统中已经具备，无需单独安装。只需要安装适配的pytorch即可。\n",
    "\n",
    "* Question4，为什么有些可以在Mac Intel芯片电脑安装的软件不能在Mac M1芯片电脑上安装？\n",
    "\n",
    "Mac M1芯片为了追求高性能和节能，在底层设计上使用的是一种叫做arm架构的精简指令集，不同于Intel等常用CPU芯片采用的x86架构完整指令集。所以有些基于x86指令集开发的软件不能直接在Mac M1芯片电脑上使用。\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8k14eaodhj30vf0u0juj.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a39248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c17aa29",
   "metadata": {},
   "source": [
    "## 二，环境配置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8639e6db",
   "metadata": {},
   "source": [
    "\n",
    "0，检查mac型号\n",
    "\n",
    "点击桌面左上角mac图标——>关于本机——>概览，确定是m1芯片，了解内存大小(最好有16G以上，8G可能不太够用)。\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8k27lhkrhj30vo0fgmye.jpg) \n",
    "\n",
    "\n",
    "\n",
    "1，下载 miniforge3 (miniforge3可以理解成 miniconda/annoconda 的社区版，提供了更稳定的对M1芯片的支持)\n",
    "\n",
    "https://github.com/conda-forge/miniforge/#download\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8k24engoxj311a0ki780.jpg)\n",
    "\n",
    "备注: annoconda 在 2022年5月开始也发布了对 mac m1芯片的官方支持，但还是推荐社区发布的miniforge3，开源且更加稳定。\n",
    "\n",
    "\n",
    "2，安装 miniforge3\n",
    "\n",
    "```bash\n",
    "chmod +x ~/Downloads/Miniforge3-MacOSX-arm64.sh\n",
    "sh ~/Downloads/Miniforge3-MacOSX-arm64.sh\n",
    "source ~/miniforge3/bin/activate\n",
    "```\n",
    "\n",
    "\n",
    "3，安装 pytorch (v1.12版本已经正式支持了用于mac m1芯片gpu加速的mps后端。)\n",
    "\n",
    "```\n",
    "pip install torch>=1.12 -i https://pypi.tuna.tsinghua.edu.cn/simple \n",
    "\n",
    "```\n",
    "\n",
    "4，测试环境\n",
    "\n",
    "```python\n",
    "import torch \n",
    "\n",
    "print(torch.backends.mps.is_available()) \n",
    "print(torch.backends.mps.is_built())\n",
    "```\n",
    "如果输出都是True的话，那么恭喜你配置成功了。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab870fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d45bae58",
   "metadata": {},
   "source": [
    "## 三，范例代码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8c8fa6",
   "metadata": {},
   "source": [
    "下面以mnist手写数字识别为例，演示使用mac M1芯片GPU的mps后端来加速pytorch的完整流程。\n",
    "\n",
    "核心操作非常简单，和使用cuda类似，训练前把模型和数据都移动到torch.device(\"mps\")就可以了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c32f563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "================================================================================2022-12-02 21:27:39\n",
      "Epoch 1 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 469/469 [00:36<00:00, 13.00it/s, train_acc=0.766, train_loss=0.81]\n",
      "100%|████████████████████████████████| 79/79 [00:01<00:00, 42.58it/s, val_acc=0.956, val_loss=0.144]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:28:17\n",
      "Epoch 2 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "<<<<<< reach best val_acc : 0.9558000564575195 >>>>>>\n",
      "100%|██████████████████████████| 469/469 [00:33<00:00, 13.93it/s, train_acc=0.959, train_loss=0.138]\n",
      "100%|████████████████████████████████| 79/79 [00:01<00:00, 44.61it/s, val_acc=0.968, val_loss=0.108]\n",
      "<<<<<< reach best val_acc : 0.968000054359436 >>>>>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:28:52\n",
      "Epoch 3 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 469/469 [00:33<00:00, 13.98it/s, train_acc=0.964, train_loss=0.123]\n",
      "100%|███████████████████████████████| 79/79 [00:01<00:00, 44.79it/s, val_acc=0.978, val_loss=0.0732]\n",
      "<<<<<< reach best val_acc : 0.9783000349998474 >>>>>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:29:28\n",
      "Epoch 4 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 469/469 [00:33<00:00, 13.96it/s, train_acc=0.968, train_loss=0.11]\n",
      "100%|███████████████████████████████| 79/79 [00:01<00:00, 44.51it/s, val_acc=0.977, val_loss=0.0863]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:30:03\n",
      "Epoch 5 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████| 469/469 [00:33<00:00, 13.98it/s, train_acc=0.966, train_loss=0.118]\n",
      "100%|████████████████████████████████| 79/79 [00:01<00:00, 44.28it/s, val_acc=0.971, val_loss=0.103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:30:38\n",
      "Epoch 6 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 469/469 [00:33<00:00, 13.98it/s, train_acc=0.958, train_loss=0.15]\n",
      "100%|███████████████████████████████| 79/79 [00:01<00:00, 44.15it/s, val_acc=0.972, val_loss=0.0903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:31:14\n",
      "Epoch 7 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 469/469 [00:33<00:00, 13.99it/s, train_acc=0.245, train_loss=inf]\n",
      "100%|██████████████████████████████████| 79/79 [00:01<00:00, 44.49it/s, val_acc=0.114, val_loss=2.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:31:49\n",
      "Epoch 8 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████| 469/469 [00:33<00:00, 14.18it/s, train_acc=0.982, train_loss=0.0575]\n",
      "100%|████████████████████████████████| 79/79 [00:01<00:00, 46.04it/s, val_acc=0.981, val_loss=0.065]\n",
      "<<<<<< reach best val_acc : 0.9807000756263733 >>>>>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:32:24\n",
      "Epoch 9 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 469/469 [00:33<00:00, 14.20it/s, train_acc=0.985, train_loss=0.0474]\n",
      "100%|███████████████████████████████| 79/79 [00:01<00:00, 44.78it/s, val_acc=0.979, val_loss=0.0678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:32:59\n",
      "Epoch 10 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 469/469 [00:33<00:00, 14.18it/s, train_acc=0.981, train_loss=0.06]\n",
      "100%|████████████████████████████████| 79/79 [00:01<00:00, 43.97it/s, val_acc=0.98, val_loss=0.0664]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:33:34\n",
      "Epoch 11 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████| 469/469 [00:33<00:00, 14.12it/s, train_acc=0.98, train_loss=0.0642]\n",
      "100%|███████████████████████████████| 79/79 [00:01<00:00, 45.20it/s, val_acc=0.975, val_loss=0.0896]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:34:09\n",
      "Epoch 12 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████| 469/469 [00:33<00:00, 14.18it/s, train_acc=0.975, train_loss=0.0832]\n",
      "100%|███████████████████████████████| 79/79 [00:01<00:00, 45.62it/s, val_acc=0.978, val_loss=0.0702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:34:44\n",
      "Epoch 13 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 469/469 [00:33<00:00, 14.20it/s, train_acc=0.969, train_loss=0.101]\n",
      "100%|███████████████████████████████| 79/79 [00:01<00:00, 44.81it/s, val_acc=0.979, val_loss=0.0701]\n",
      "<<<<<< val_acc without improvement in 5 epoch, early stopping >>>>>>\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "import torchvision \n",
    "from torchvision import transforms \n",
    "import torch.nn.functional as F \n",
    "\n",
    "\n",
    "import os,sys,time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime \n",
    "from tqdm import tqdm \n",
    "from copy import deepcopy\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "\n",
    "def printlog(info):\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "    print(str(info)+\"\\n\")\n",
    "    \n",
    "    \n",
    "#================================================================================\n",
    "# 一，准备数据\n",
    "#================================================================================\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "ds_train = torchvision.datasets.MNIST(root=\"mnist/\",train=True,download=True,transform=transform)\n",
    "ds_val = torchvision.datasets.MNIST(root=\"mnist/\",train=False,download=True,transform=transform)\n",
    "\n",
    "dl_train =  torch.utils.data.DataLoader(ds_train, batch_size=128, shuffle=True, num_workers=2)\n",
    "dl_val =  torch.utils.data.DataLoader(ds_val, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "#================================================================================\n",
    "# 二，定义模型\n",
    "#================================================================================\n",
    "\n",
    "\n",
    "def create_net():\n",
    "    net = nn.Sequential()\n",
    "    net.add_module(\"conv1\",nn.Conv2d(in_channels=1,out_channels=64,kernel_size = 3))\n",
    "    net.add_module(\"pool1\",nn.MaxPool2d(kernel_size = 2,stride = 2))\n",
    "    net.add_module(\"conv2\",nn.Conv2d(in_channels=64,out_channels=512,kernel_size = 3))\n",
    "    net.add_module(\"pool2\",nn.MaxPool2d(kernel_size = 2,stride = 2))\n",
    "    net.add_module(\"dropout\",nn.Dropout2d(p = 0.1))\n",
    "    net.add_module(\"adaptive_pool\",nn.AdaptiveMaxPool2d((1,1)))\n",
    "    net.add_module(\"flatten\",nn.Flatten())\n",
    "    net.add_module(\"linear1\",nn.Linear(512,1024))\n",
    "    net.add_module(\"relu\",nn.ReLU())\n",
    "    net.add_module(\"linear2\",nn.Linear(1024,10))\n",
    "    return net\n",
    "\n",
    "net = create_net()\n",
    "print(net)\n",
    "\n",
    "# 评估指标\n",
    "class Accuracy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.correct = nn.Parameter(torch.tensor(0.0),requires_grad=False)\n",
    "        self.total = nn.Parameter(torch.tensor(0.0),requires_grad=False)\n",
    "\n",
    "    def forward(self, preds: torch.Tensor, targets: torch.Tensor):\n",
    "        preds = preds.argmax(dim=-1)\n",
    "        m = (preds == targets).sum()\n",
    "        n = targets.shape[0] \n",
    "        self.correct += m \n",
    "        self.total += n\n",
    "        \n",
    "        return m/n\n",
    "\n",
    "    def compute(self):\n",
    "        return self.correct.float() / self.total \n",
    "    \n",
    "    def reset(self):\n",
    "        self.correct -= self.correct\n",
    "        self.total -= self.total\n",
    "        \n",
    "#================================================================================\n",
    "# 三，训练模型\n",
    "#================================================================================     \n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer= torch.optim.Adam(net.parameters(),lr = 0.01)   \n",
    "metrics_dict = nn.ModuleDict({\"acc\":Accuracy()})\n",
    "\n",
    "\n",
    "# =========================移动模型到mps上==============================\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "loss_fn.to(device)\n",
    "metrics_dict.to(device)\n",
    "# ====================================================================\n",
    "\n",
    "\n",
    "epochs = 20 \n",
    "ckpt_path='checkpoint.pt'\n",
    "\n",
    "#early_stopping相关设置\n",
    "monitor=\"val_acc\"\n",
    "patience=5\n",
    "mode=\"max\"\n",
    "\n",
    "history = {}\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    printlog(\"Epoch {0} / {1}\".format(epoch, epochs))\n",
    "\n",
    "    # 1，train -------------------------------------------------  \n",
    "    net.train()\n",
    "    \n",
    "    total_loss,step = 0,0\n",
    "    \n",
    "    loop = tqdm(enumerate(dl_train), total =len(dl_train),ncols=100)\n",
    "    train_metrics_dict = deepcopy(metrics_dict) \n",
    "    \n",
    "    for i, batch in loop: \n",
    "        \n",
    "        features,labels = batch\n",
    "        \n",
    "        # =========================移动数据到mps上==============================\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # ====================================================================\n",
    "        \n",
    "        #forward\n",
    "        preds = net(features)\n",
    "        loss = loss_fn(preds,labels)\n",
    "        \n",
    "        #backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        #metrics\n",
    "        step_metrics = {\"train_\"+name:metric_fn(preds, labels).item() \n",
    "                        for name,metric_fn in train_metrics_dict.items()}\n",
    "        \n",
    "        step_log = dict({\"train_loss\":loss.item()},**step_metrics)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        step+=1\n",
    "        if i!=len(dl_train)-1:\n",
    "            loop.set_postfix(**step_log)\n",
    "        else:\n",
    "            epoch_loss = total_loss/step\n",
    "            epoch_metrics = {\"train_\"+name:metric_fn.compute().item() \n",
    "                             for name,metric_fn in train_metrics_dict.items()}\n",
    "            epoch_log = dict({\"train_loss\":epoch_loss},**epoch_metrics)\n",
    "            loop.set_postfix(**epoch_log)\n",
    "\n",
    "            for name,metric_fn in train_metrics_dict.items():\n",
    "                metric_fn.reset()\n",
    "                \n",
    "    for name, metric in epoch_log.items():\n",
    "        history[name] = history.get(name, []) + [metric]\n",
    "        \n",
    "\n",
    "    # 2，validate -------------------------------------------------\n",
    "    net.eval()\n",
    "    \n",
    "    total_loss,step = 0,0\n",
    "    loop = tqdm(enumerate(dl_val), total =len(dl_val),ncols=100)\n",
    "    \n",
    "    val_metrics_dict = deepcopy(metrics_dict) \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in loop: \n",
    "\n",
    "            features,labels = batch\n",
    "            \n",
    "            # =========================移动数据到mps上==============================\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # ====================================================================\n",
    "            \n",
    "            #forward\n",
    "            preds = net(features)\n",
    "            loss = loss_fn(preds,labels)\n",
    "\n",
    "            #metrics\n",
    "            step_metrics = {\"val_\"+name:metric_fn(preds, labels).item() \n",
    "                            for name,metric_fn in val_metrics_dict.items()}\n",
    "\n",
    "            step_log = dict({\"val_loss\":loss.item()},**step_metrics)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            step+=1\n",
    "            if i!=len(dl_val)-1:\n",
    "                loop.set_postfix(**step_log)\n",
    "            else:\n",
    "                epoch_loss = (total_loss/step)\n",
    "                epoch_metrics = {\"val_\"+name:metric_fn.compute().item() \n",
    "                                 for name,metric_fn in val_metrics_dict.items()}\n",
    "                epoch_log = dict({\"val_loss\":epoch_loss},**epoch_metrics)\n",
    "                loop.set_postfix(**epoch_log)\n",
    "\n",
    "                for name,metric_fn in val_metrics_dict.items():\n",
    "                    metric_fn.reset()\n",
    "                    \n",
    "    epoch_log[\"epoch\"] = epoch           \n",
    "    for name, metric in epoch_log.items():\n",
    "        history[name] = history.get(name, []) + [metric]\n",
    "\n",
    "    # 3，early-stopping -------------------------------------------------\n",
    "    arr_scores = history[monitor]\n",
    "    best_score_idx = np.argmax(arr_scores) if mode==\"max\" else np.argmin(arr_scores)\n",
    "    if best_score_idx==len(arr_scores)-1:\n",
    "        torch.save(net.state_dict(),ckpt_path)\n",
    "        print(\"<<<<<< reach best {0} : {1} >>>>>>\".format(monitor,\n",
    "             arr_scores[best_score_idx]),file=sys.stderr)\n",
    "    if len(arr_scores)-best_score_idx>patience:\n",
    "        print(\"<<<<<< {} without improvement in {} epoch, early stopping >>>>>>\".format(\n",
    "            monitor,patience),file=sys.stderr)\n",
    "        break \n",
    "    net.load_state_dict(torch.load(ckpt_path))\n",
    "    \n",
    "dfhistory = pd.DataFrame(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b7fdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "817c0ca1-dfdc-42f3-a660-b34b096ac2d4",
   "metadata": {},
   "source": [
    "## 四，使用torchkeras支持Mac M1芯片加速"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8527a167-02c8-4980-ac1d-ecece961616b",
   "metadata": {},
   "source": [
    "我在最新的3.3.0的torchkeras版本中引入了对 mac m1芯片的支持，当存在可用的 mac m1芯片/ GPU 时，会默认使用它们进行加速，无需做任何配置。\n",
    "\n",
    "使用范例如下。😋😋😋\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cb81b0e-5a0a-42cb-831d-b701f2b768af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchkeras\n",
      "  Downloading torchkeras-3.3.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: torchkeras\n",
      "Successfully installed torchkeras-3.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchkeras>=3.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfa97081-8940-41c3-9283-ea0c5444efda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n",
      "--------------------------------------------------------------------------\n",
      "Layer (type)                            Output Shape              Param #\n",
      "==========================================================================\n",
      "Conv2d-1                            [-1, 64, 26, 26]                  640\n",
      "MaxPool2d-2                         [-1, 64, 13, 13]                    0\n",
      "Conv2d-3                           [-1, 512, 11, 11]              295,424\n",
      "MaxPool2d-4                          [-1, 512, 5, 5]                    0\n",
      "Dropout2d-5                          [-1, 512, 5, 5]                    0\n",
      "AdaptiveMaxPool2d-6                  [-1, 512, 1, 1]                    0\n",
      "Flatten-7                                  [-1, 512]                    0\n",
      "Linear-8                                  [-1, 1024]              525,312\n",
      "ReLU-9                                    [-1, 1024]                    0\n",
      "Linear-10                                   [-1, 10]               10,250\n",
      "==========================================================================\n",
      "Total params: 831,626\n",
      "Trainable params: 831,626\n",
      "Non-trainable params: 0\n",
      "--------------------------------------------------------------------------\n",
      "Input size (MB): 0.000069\n",
      "Forward/backward pass size (MB): 1.104080\n",
      "Params size (MB): 3.172401\n",
      "Estimated Total Size (MB): 4.276550\n",
      "--------------------------------------------------------------------------\n",
      "\u001b[0;31m<<<<<< ⚡️ mps is used >>>>>>\u001b[0m\n",
      "\n",
      "================================================================================2022-12-02 22:17:29\n",
      "Epoch 1 / 15\n",
      "\n",
      "100%|██████████████████████████| 469/469 [00:33<00:00, 13.89it/s, train_acc=0.903, train_loss=0.304]\n",
      "100%|███████████████████████████████| 79/79 [00:01<00:00, 44.44it/s, val_acc=0.973, val_loss=0.0884]\n",
      "\u001b[0;31m<<<<<< reach best val_acc : 0.9730000495910645 >>>>>>\u001b[0m\n",
      "\n",
      "================================================================================2022-12-02 22:18:05\n",
      "Epoch 2 / 15\n",
      "\n",
      "100%|█████████████████████████| 469/469 [00:33<00:00, 14.09it/s, train_acc=0.974, train_loss=0.0823]\n",
      "100%|███████████████████████████████| 79/79 [00:01<00:00, 45.71it/s, val_acc=0.979, val_loss=0.0662]\n",
      "\u001b[0;31m<<<<<< reach best val_acc : 0.9794000387191772 >>>>>>\u001b[0m\n",
      "\n",
      "================================================================================2022-12-02 22:18:40\n",
      "Epoch 3 / 15\n",
      "\n",
      "100%|█████████████████████████| 469/469 [00:32<00:00, 14.22it/s, train_acc=0.982, train_loss=0.0553]\n",
      "100%|███████████████████████████████| 79/79 [00:01<00:00, 44.59it/s, val_acc=0.981, val_loss=0.0699]\n",
      "\u001b[0;31m<<<<<< reach best val_acc : 0.9808000326156616 >>>>>>\u001b[0m\n",
      "\n",
      "================================================================================2022-12-02 22:19:15\n",
      "Epoch 4 / 15\n",
      "\n",
      "100%|█████████████████████████| 469/469 [00:32<00:00, 14.21it/s, train_acc=0.986, train_loss=0.0434]\n",
      "100%|███████████████████████████████| 79/79 [00:01<00:00, 44.89it/s, val_acc=0.988, val_loss=0.0382]\n",
      "\u001b[0;31m<<<<<< reach best val_acc : 0.9883000254631042 >>>>>>\u001b[0m\n",
      "\n",
      "================================================================================2022-12-02 22:19:49\n",
      "Epoch 5 / 15\n",
      "\n",
      "100%|█████████████████████████| 469/469 [00:32<00:00, 14.22it/s, train_acc=0.989, train_loss=0.0326]\n",
      "100%|███████████████████████████████| 79/79 [00:01<00:00, 44.56it/s, val_acc=0.987, val_loss=0.0429]\n",
      "\n",
      "================================================================================2022-12-02 22:20:24\n",
      "Epoch 6 / 15\n",
      "\n",
      "100%|██████████████████████████| 469/469 [00:35<00:00, 13.13it/s, train_acc=0.99, train_loss=0.0313]\n",
      "100%|███████████████████████████████| 79/79 [00:01<00:00, 43.52it/s, val_acc=0.987, val_loss=0.0486]\n",
      "\n",
      "================================================================================2022-12-02 22:21:02\n",
      "Epoch 7 / 15\n",
      "\n",
      "100%|█████████████████████████| 469/469 [00:32<00:00, 14.32it/s, train_acc=0.991, train_loss=0.0255]\n",
      "100%|███████████████████████████████| 79/79 [00:01<00:00, 43.23it/s, val_acc=0.986, val_loss=0.0591]\n",
      "\n",
      "================================================================================2022-12-02 22:21:36\n",
      "Epoch 8 / 15\n",
      "\n",
      "100%|█████████████████████████| 469/469 [00:32<00:00, 14.27it/s, train_acc=0.994, train_loss=0.0199]\n",
      "100%|███████████████████████████████| 79/79 [00:01<00:00, 45.32it/s, val_acc=0.985, val_loss=0.0542]\n",
      "\n",
      "================================================================================2022-12-02 22:22:11\n",
      "Epoch 9 / 15\n",
      "\n",
      "100%|█████████████████████████| 469/469 [00:32<00:00, 14.28it/s, train_acc=0.993, train_loss=0.0228]\n",
      "100%|███████████████████████████████| 79/79 [00:01<00:00, 43.70it/s, val_acc=0.987, val_loss=0.0471]\n",
      "\u001b[0;31m<<<<<< val_acc without improvement in 5 epoch, early stopping >>>>>>\u001b[0m\n",
      "   train_loss  train_acc  val_loss  val_acc  epoch\n",
      "0    0.303751   0.903283  0.088422   0.9730      1\n",
      "1    0.082336   0.973917  0.066228   0.9794      2\n",
      "2    0.055266   0.982233  0.069914   0.9808      3\n",
      "3    0.043367   0.985983  0.038230   0.9883      4\n",
      "4    0.032618   0.989317  0.042920   0.9869      5\n",
      "5    0.031270   0.989533  0.048605   0.9871      6\n",
      "6    0.025532   0.991283  0.059145   0.9862      7\n",
      "7    0.019919   0.993550  0.054234   0.9853      8\n",
      "8    0.022779   0.992517  0.047057   0.9874      9\n",
      "100%|███████████████████████████████| 79/79 [00:01<00:00, 42.95it/s, val_acc=0.988, val_loss=0.0382]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchkeras #Attention this line \n",
    "\n",
    "\n",
    "#================================================================================\n",
    "# 一，准备数据\n",
    "#================================================================================\n",
    "\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "ds_train = torchvision.datasets.MNIST(root=\"mnist/\",train=True,download=True,transform=transform)\n",
    "ds_val = torchvision.datasets.MNIST(root=\"mnist/\",train=False,download=True,transform=transform)\n",
    "dl_train =  torch.utils.data.DataLoader(ds_train, batch_size=128, shuffle=True, num_workers=2)\n",
    "dl_val =  torch.utils.data.DataLoader(ds_val, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "for features,labels in dl_train:\n",
    "    break \n",
    "\n",
    "#================================================================================\n",
    "# 二，定义模型\n",
    "#================================================================================\n",
    "\n",
    "\n",
    "def create_net():\n",
    "    net = nn.Sequential()\n",
    "    net.add_module(\"conv1\",nn.Conv2d(in_channels=1,out_channels=64,kernel_size = 3))\n",
    "    net.add_module(\"pool1\",nn.MaxPool2d(kernel_size = 2,stride = 2))\n",
    "    net.add_module(\"conv2\",nn.Conv2d(in_channels=64,out_channels=512,kernel_size = 3))\n",
    "    net.add_module(\"pool2\",nn.MaxPool2d(kernel_size = 2,stride = 2))\n",
    "    net.add_module(\"dropout\",nn.Dropout2d(p = 0.1))\n",
    "    net.add_module(\"adaptive_pool\",nn.AdaptiveMaxPool2d((1,1)))\n",
    "    net.add_module(\"flatten\",nn.Flatten())\n",
    "    net.add_module(\"linear1\",nn.Linear(512,1024))\n",
    "    net.add_module(\"relu\",nn.ReLU())\n",
    "    net.add_module(\"linear2\",nn.Linear(1024,10))\n",
    "    return net\n",
    "\n",
    "net = create_net()\n",
    "print(net)\n",
    "\n",
    "# 评估指标\n",
    "class Accuracy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.correct = nn.Parameter(torch.tensor(0.0),requires_grad=False)\n",
    "        self.total = nn.Parameter(torch.tensor(0.0),requires_grad=False)\n",
    "\n",
    "    def forward(self, preds: torch.Tensor, targets: torch.Tensor):\n",
    "        preds = preds.argmax(dim=-1)\n",
    "        m = (preds == targets).sum()\n",
    "        n = targets.shape[0] \n",
    "        self.correct += m \n",
    "        self.total += n\n",
    "        \n",
    "        return m/n\n",
    "\n",
    "    def compute(self):\n",
    "        return self.correct.float() / self.total \n",
    "    \n",
    "    def reset(self):\n",
    "        self.correct -= self.correct\n",
    "        self.total -= self.total\n",
    "        \n",
    "\n",
    "\n",
    "#================================================================================\n",
    "# 三，训练模型\n",
    "#================================================================================\n",
    "\n",
    "model = torchkeras.KerasModel(net,\n",
    "      loss_fn = nn.CrossEntropyLoss(),\n",
    "      optimizer= torch.optim.Adam(net.parameters(),lr=0.001),\n",
    "      metrics_dict = {\"acc\":Accuracy()}\n",
    "    )\n",
    "\n",
    "from torchkeras import summary\n",
    "summary(model,input_data=features);\n",
    "\n",
    "\n",
    "# if gpu/mps is available, will auto use it, otherwise cpu will be used.\n",
    "\n",
    "dfhistory=model.fit(train_data=dl_train, \n",
    "                    val_data=dl_val, \n",
    "                    epochs=15, \n",
    "                    patience=5, \n",
    "                    monitor=\"val_acc\",mode=\"max\",\n",
    "                    ckpt_path='checkpoint.pt')\n",
    "\n",
    "#================================================================================\n",
    "# 四，评估模型\n",
    "#================================================================================\n",
    "\n",
    "model.evaluate(dl_val)\n",
    "\n",
    "\n",
    "#================================================================================\n",
    "# 五，使用模型\n",
    "#================================================================================\n",
    "\n",
    "model.predict(dl_val)[0:10]\n",
    "\n",
    "#================================================================================\n",
    "# 六，保存模型\n",
    "#================================================================================\n",
    "# The best net parameters  has been saved at ckpt_path='checkpoint.pt' during training.\n",
    "net_clone = create_net() \n",
    "net_clone.load_state_dict(torch.load(\"checkpoint.pt\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c94a1-8df1-4c2e-a131-578588792967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9f63aa-2dc8-4004-bbbf-062b42aab800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddbfb751",
   "metadata": {},
   "source": [
    "## 五，M1芯片与CPU和Nvidia GPU速度对比"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77f25cd-53a2-44a3-b308-9cafa045ee60",
   "metadata": {},
   "source": [
    "使用以上代码作为范例，分别在CPU, mac m1芯片，以及Nvidia GPU上 运行。\n",
    "\n",
    "得到的运行速度截图如下：\n",
    "\n",
    "纯CPU跑效果\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8pu8qudibj318i0d0n06.jpg)\n",
    "\n",
    "Mac M1 芯片加速效果\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8pubdxbrkj318u0eywhq.jpg)\n",
    "\n",
    "\n",
    "Tesla P100 GPU加速效果\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8pu9epg15j319i0dcn0c.jpg)\n",
    "\n",
    "\n",
    "纯CPU跑一个epoch大约是3min 18s。\n",
    "\n",
    "使用mac m1芯片加速，一个epoch大约是33 s，相比CPU跑，加速约6倍。\n",
    "\n",
    "使用Nvidia Tesla P100 GPU加速，一个epoch大约是 8s，相比CPU跑，加速约25倍。\n",
    "\n",
    "这和pytorch官网显示的训练过程平均加速7倍相当。\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8putb28ivj30zk0lwq4j.jpg)\n",
    "\n",
    "整体来说Mac M1芯片对 深度学习训练过程的加速还是非常显著的，通常达到5到7倍左右。\n",
    "\n",
    "不过目前看和企业中最常使用的高端的Tesla P100 GPU相比，还是有2到4倍的训练速度差异，可以视做一个mini版的GPU吧。\n",
    "\n",
    "因此Mac M1芯片比较适合本地训练一些中小规模的模型，快速迭代idea，使用起来还是蛮香的。\n",
    "\n",
    "尤其是本来就打算想换个电脑的，用mac做开发本来比windows好使多了。\n",
    "\n",
    "有需要的小伙伴推荐买这个，京东自营的渠道，Mac Book Pro M1芯片，16G统一内存，小型炼丹基本够用。\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8pw5ijnfuj30qi0z30uf.jpg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
